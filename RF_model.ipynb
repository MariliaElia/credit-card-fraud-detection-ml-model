{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "#Preprocessing Libraries\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Model Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from VAE import VAE_oversampling\n",
    "from GAN import GAN\n",
    "from CV import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the random seed \n",
    "import random\n",
    "seed = 42\n",
    "np.random.seed(seed) \n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class'], axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "#Split data initially to train and remainingfor cross\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, stratify=y)\n",
    "\n",
    "# Check the number of records\n",
    "print('The number of records in the training dataset is', X_train.shape[0])\n",
    "print('The number of records in the validation dataset is', X_test.shape[0])\n",
    "print(f\"The training dataset has {sorted(Counter(y_train).items())[0][1]} records for the majority class and {sorted(Counter(y_train).items())[1][1]} records for the minority class.\")\n",
    "print(f\"The validation and test datasets have {sorted(Counter(y_test).items())[0][1]} records for the majority class and {sorted(Counter(y_test).items())[1][1]} records for the minority class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = copy.deepcopy(X_train)\n",
    "X_test_processed = copy.deepcopy(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_processed = pd.DataFrame(scaler.fit_transform(X_train_processed[:]), index=X_train_processed.index)\n",
    "X_test_processed = pd.DataFrame(scaler.transform(X_test_processed[:]), index=X_test_processed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=1)\n",
    "\n",
    "#transform the dataset\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_procesed_smote = pd.DataFrame(scaler.fit_transform(X_train_smote[:]), index=X_train_smote.index)\n",
    "X_test_processed_smote = pd.DataFrame(scaler.transform(X_test[:]), index=X_test.index)\n",
    "\n",
    "counter = Counter(y_train_smote)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(random_state=1)\n",
    "\n",
    "#transform the dataset\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_processed_adasyn = pd.DataFrame(scaler.fit_transform(X_train_adasyn[:]), index=X_train_adasyn.index)\n",
    "X_test_processed_adasyn = pd.DataFrame(scaler.transform(X_test[:]), index=X_test.index)\n",
    "\n",
    "counter = Counter(y_train_adasyn)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "model_cv(X_train, y_train, rf)\n",
    "\n",
    "print(\"\\n############### Evaluate model ###############\")\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "evaluate_model(X_test_processed, y_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "model_cv(X_train, y_train, rf, 'smote')\n",
    "\n",
    "print(\"\\n############### Evaluate model ###############\")\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_procesed_smote, y_train_smote)\n",
    "\n",
    "evaluate_model(X_test_processed_smote, y_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "model_cv(X_train, y_train, rf, 'adasyn')\n",
    "\n",
    "print(\"\\n############### Evaluate model ###############\")\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_processed_adasyn, y_train_adasyn)\n",
    "\n",
    "evaluate_model(X_test_processed_adasyn, y_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation with VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "lst_accuracy = []\n",
    "lst_precision = []\n",
    "lst_recall = []\n",
    "lst_f1_score = []\n",
    "lst_roc_auc_score = []\n",
    "\n",
    "lst_accuracy_train = []\n",
    "lst_precision_train = []\n",
    "lst_recall_train = []\n",
    "lst_f1_score_train = []\n",
    "lst_roc_auc_score_train = []\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "for count, (train_index, valid_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(\"------------------------ KFold:\", count+1, \"---------------------------\")\n",
    "    X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "    print(f\"The training dataset has {sorted(Counter(y_train_fold).items())[0][1]} records for the majority class and {sorted(Counter(y_train_fold).items())[1][1]} records for the minority class.\")\n",
    "    print(f\"The test dataset has {sorted(Counter(y_valid_fold).items())[0][1]} records for the majority class and {sorted(Counter(y_valid_fold).items())[1][1]} records for the minority class.\")\n",
    "    \n",
    "    maj = len(y_train_fold[y_train_fold == 0])\n",
    "    mino = len(y_train_fold[y_train_fold == 1])\n",
    "    frac = 0.5\n",
    "    num_samples = round(1/(1/frac - 1) * maj - mino)\n",
    "\n",
    "    print(\"NUmber of samples to be generated: \", num_samples)\n",
    "\n",
    "    # Variational Oversampling \n",
    "    vos = VAE_oversampling(hidden_dim=32,\n",
    "                            latent_dim=10,\n",
    "                            original_dim=30,\n",
    "                            minority_class_id=1,\n",
    "                            epochs=100,\n",
    "                            batch_size=1,\n",
    "                            num_samples_to_generate = num_samples,\n",
    "                            random_state=0,\n",
    "                            optimizer=\"adam\")\n",
    "\n",
    "    #Fit the VAE oversampling model and get new data set\n",
    "    X_res_val,y_res_val = vos.fit_sample(X_train_fold,y_train_fold)\n",
    "    \n",
    "    std = StandardScaler()\n",
    "    \n",
    "    X_train_processed = std.fit_transform(X_res_val) \n",
    "    X_valid_processed = std.transform(X_valid_fold)\n",
    "\n",
    "    model.fit(X_train_processed, y_res_val)\n",
    "\n",
    "    train_predictions = model.predict(X_train_processed)\n",
    "\n",
    "    y_pred_test = model.predict(X_valid_processed)\n",
    "\n",
    "    lst_accuracy.append(accuracy_score(y_valid_fold, y_pred_test))\n",
    "    lst_precision.append(precision_score(y_valid_fold, y_pred_test))\n",
    "    lst_recall.append(recall_score(y_valid_fold, y_pred_test))\n",
    "    lst_f1_score.append(f1_score(y_valid_fold, y_pred_test))\n",
    "    lst_roc_auc_score.append(roc_auc_score(y_valid_fold, y_pred_test))\n",
    "\n",
    "    lst_accuracy_train.append(accuracy_score(y_res_val, train_predictions))\n",
    "    lst_precision_train.append(precision_score(y_res_val, train_predictions))\n",
    "    lst_recall_train.append(recall_score(y_res_val, train_predictions))\n",
    "    lst_f1_score_train.append(f1_score(y_res_val, train_predictions))\n",
    "    lst_roc_auc_score_train.append(roc_auc_score(y_res_val, train_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('############ Validation #############')\n",
    "print(f\"Accuracy:, {np.mean(lst_accuracy):0.6f} (+/- {np.std(lst_accuracy):0.6f})\")\n",
    "print(f\"Precision: {np.mean(lst_precision):0.6f} (+/- {np.std(lst_precision):0.6f})\")\n",
    "print(f\"Recall: {np.mean(lst_recall):0.6f} (+/- {np.std(lst_recall):0.6f})\")\n",
    "print(f\"F1 score: {np.mean(lst_f1_score):0.6f} (+/- {np.std(lst_f1_score):0.6f})\")\n",
    "print(f\"ROC_AUC: {np.mean(lst_roc_auc_score):0.6f} (+/- {np.std(lst_roc_auc_score):0.6f})\")\n",
    "\n",
    "print('############ Training #############')\n",
    "print(f\"Accuracy:, {np.mean(lst_accuracy_train):0.6f} (+/- {np.std(lst_accuracy_train):0.6f})\")\n",
    "print(f\"Precision: {np.mean(lst_precision_train):0.6f} (+/- {np.std(lst_precision_train):0.6f})\")\n",
    "print(f\"Recall: {np.mean(lst_recall_train):0.6f} (+/- {np.std(lst_recall_train):0.6f})\")\n",
    "print(f\"F1 score: {np.mean(lst_f1_score_train):0.6f} (+/- {np.std(lst_f1_score_train):0.6f})\")\n",
    "print(f\"ROC_AUC: {np.mean(lst_roc_auc_score_train):0.6f} (+/- {np.std(lst_roc_auc_score_train):0.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "maj = len(y_train[y_train == 0])\n",
    "mino = len(y_train[y_train == 1])\n",
    "frac = 0.5\n",
    "num_samples = round(1/(1/frac - 1) * maj - mino)\n",
    "\n",
    "vos = VAE_oversampling(hidden_dim=32,\n",
    "                        latent_dim=10,\n",
    "                        original_dim=30,\n",
    "                        minority_class_id=1,\n",
    "                        epochs=100,\n",
    "                        batch_size=1,\n",
    "                        num_samples_to_generate = num_samples,\n",
    "                        random_state = 0,\n",
    "                        optimizer=\"adam\")\n",
    "\n",
    "#Fit the VAE oversampling model and get new data set\n",
    "X_res_val,y_res_val = vos.fit_sample(X_train,y_train)\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "X_train_processed = std.fit_transform(X_res_val) \n",
    "X_test_processed = std.transform(X_test)\n",
    "\n",
    "rf.fit(X_train_processed, y_res_val)\n",
    "\n",
    "train_predictions = rf.predict(X_train_processed)\n",
    "print(\"################# Training Results ########################\")\n",
    "model_scores(y_res_val, train_predictions)\n",
    "\n",
    "evaluate_model(X_test_processed, y_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation with GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "lst_accuracy = []\n",
    "lst_precision = []\n",
    "lst_recall = []\n",
    "lst_f1_score = []\n",
    "lst_roc_auc_score = []\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "for count, (train_index, valid_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(\"------------------------ KFold:\", count+1, \"---------------------------\")\n",
    "    X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "    print(f\"The training dataset has {sorted(Counter(y_train_fold).items())[0][1]} records for the majority class and {sorted(Counter(y_train_fold).items())[1][1]} records for the minority class.\")\n",
    "    print(f\"The test dataset has {sorted(Counter(y_valid_fold).items())[0][1]} records for the majority class and {sorted(Counter(y_valid_fold).items())[1][1]} records for the minority class.\")\n",
    "    \n",
    "    maj = len(y_train_fold[y_train_fold == 0])\n",
    "    mino = len(y_train_fold[y_train_fold == 1])\n",
    "    frac = 0.5\n",
    "    num_samples = round(1/(1/frac - 1) * maj - mino)\n",
    "\n",
    "    print(\"NUmber of samples to be generated: \", num_samples)\n",
    "\n",
    "    gan = GAN(generator_output_dim=30, \n",
    "              discriminator_input_dim=30,\n",
    "              noise_dim=100,\n",
    "              num_samples=num_samples, \n",
    "              epochs=100, \n",
    "              batch_size=24,\n",
    "              dropout=0.4)\n",
    "\n",
    "    #Fit the GAN oversampling model and get new data set\n",
    "    X_res_val_gan,y_res_val_gan = gan.fit_sample(X_train_fold, y_train_fold)\n",
    "\n",
    "    std = StandardScaler()\n",
    "    \n",
    "    X_train_processed = std.fit_transform(X_res_val_gan) \n",
    "    X_valid_processed = std.transform(X_valid_fold)\n",
    "\n",
    "    model.fit(X_train_processed, y_res_val_gan)\n",
    "\n",
    "    y_pred_test = model.predict(X_valid_processed)\n",
    "\n",
    "    lst_accuracy.append(accuracy_score(y_valid_fold, y_pred_test))\n",
    "    lst_precision.append(precision_score(y_valid_fold, y_pred_test))\n",
    "    lst_recall.append(recall_score(y_valid_fold, y_pred_test))\n",
    "    lst_f1_score.append(f1_score(y_valid_fold, y_pred_test))\n",
    "    lst_roc_auc_score.append(roc_auc_score(y_valid_fold, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy:, {np.mean(lst_accuracy):0.6f} (+/- {np.std(lst_accuracy):0.6f})\")\n",
    "print(f\"Precision: {np.mean(lst_precision):0.6f} (+/- {np.std(lst_precision):0.6f})\")\n",
    "print(f\"Recall: {np.mean(lst_recall):0.6f} (+/- {np.std(lst_recall):0.6f})\")\n",
    "print(f\"F1 score: {np.mean(lst_f1_score):0.6f} (+/- {np.std(lst_f1_score):0.6f})\")\n",
    "print(f\"ROC_AUC: {np.mean(lst_roc_auc_score):0.6f} (+/- {np.std(lst_roc_auc_score):0.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "maj = len(y_train[y_train == 0])\n",
    "mino = len(y_train[y_train == 1])\n",
    "frac = 0.5\n",
    "num_samples = round(1/(1/frac - 1) * maj - mino)\n",
    "\n",
    "gan = GAN(generator_output_dim=30, \n",
    "              discriminator_input_dim=30,\n",
    "              noise_dim=100,\n",
    "              num_samples=num_samples, \n",
    "              epochs=100, \n",
    "              batch_size=24,\n",
    "              dropout=0.4)\n",
    "\n",
    "\n",
    "X_res_val_gan,y_res_val_gan = gan.fit_sample(X_train, y_train)\n",
    "\n",
    "std = StandardScaler()\n",
    "    \n",
    "X_train_processed = std.fit_transform(X_res_val_gan) \n",
    "X_test_processed = std.transform(X_test)\n",
    "\n",
    "rf.fit(X_train_processed, y_res_val_gan)\n",
    "\n",
    "train_predictions = rf.predict(X_train_processed)\n",
    "print(\"################# Training Results ########################\")\n",
    "model_scores(y_res_val_gan, train_predictions)\n",
    "\n",
    "evaluate_model(X_test_processed, y_test, rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
